{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AI Report William Forber:22015706</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from keras import layers\n",
    "from baseline_model import base_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the constants reading the dataset, categorising labels\n",
    "<p>\n",
    "Here I'm setting the constant for the k-fold-crossvalidation to use 5 folds, this will be used to train and evaluate the models using different train-test data for a more robust evaluation for each models performance.\n",
    "</p>\n",
    "<p>\n",
    "I'm also reading in the dataset and catagorising the labels, which will be used to pre-process the dataset with the redundant labels being removed, and the category labels being used with pandas dummies features and the numerical features. Categorising them here makes it easier to change in the future.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "test_results = []\n",
    "k_fold = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "dataset = pd.read_csv('../Dataset/Synthetic_Data_For_Students.csv')\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "redundant_labels = ['Accident Description', 'Injury Description', 'Claim Date', 'Accident Date',\n",
    "                    'SpecialHealthExpenses', 'SpecialReduction', 'SpecialOverage', 'GeneralRest',\n",
    "                    'SpecialAdditionalInjury', 'SpecialEarningsLoss', 'SpecialUsageLoss', 'SpecialMedications',\n",
    "                    'SpecialAssetDamage', 'SpecialRehabilitation', 'SpecialFixes', 'GeneralFixed', 'GeneralUplift',\n",
    "                    'SpecialLoanerVehicle', 'SpecialTripCosts', 'SpecialJourneyExpenses', 'SpecialTherapy']\n",
    "\n",
    "category_labels = ['AccidentType', 'Exceptional_Circumstances', 'Minor_Psychological_Injury', 'Dominant injury',\n",
    "                   'Whiplash', 'Vehicle Type', 'Weather Conditions',\n",
    "                   'Police Report Filed', 'Witness Present', 'Gender']\n",
    "\n",
    "numerical_labels = ['SettlementValue', 'Injury_Prognosis',\n",
    "                    'Vehicle Age', 'Driver Age', 'Number of Passengers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions for pre-processing the dataset, and evaluating the models\n",
    "<p>\n",
    "Here I'm defining the functions to pre-process the dataset, since the dataset will contain invalid data I'm deleting all rows that contain null values, the next function uses the pandas dummies feature to go though the category labels and adding them to the new pandas dataframe while deleting the original column, allowing for these values to be usefull when training.\n",
    "</p>\n",
    "<p>\n",
    "So in a nutshell, I'm going through each redundant label, removing it from the dataframe, scaling the data to prevent anomalies from influencing the model quality, using pandas dummies to catagorise data like gender etc, defining the build model funciton which takes in hyper parameters for the tuned model, and finally I'm using k-fold cross validation for validating each model which uses different training data and test data to get a more meaningful comparison between models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset(data):\n",
    "    data.dropna(inplace=True)\n",
    "    data.drop(redundant_labels, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def categorise_data(data, label):\n",
    "    categories = pd.get_dummies(data[label])\n",
    "    data.drop(label, axis=1, inplace=True)\n",
    "    data = pd.concat([data, categories], axis=1)\n",
    "    return data\n",
    "\n",
    "def extract_months(prognosis):\n",
    "    return int(''.join(filter(str.isdigit, prognosis)))\n",
    "\n",
    "\n",
    "def scale_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_labels] = scaler.fit_transform(data[numerical_labels])\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data = clean_dataset(data)\n",
    "    data['Injury_Prognosis'] = data['Injury_Prognosis'].apply(extract_months)\n",
    "    data = scale_data(data)\n",
    "    for label in category_labels:\n",
    "        data = categorise_data(data, label)\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_model(hyper_parameters, input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(hyper_parameters.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "                           activation=hyper_parameters.Choice(\n",
    "                               'activation_1', ['relu', 'tanh', 'leaky_relu']),\n",
    "                           # Pass input_shape explicitly\n",
    "                           input_shape=(input_shape,)))\n",
    "\n",
    "    for i in range(hyper_parameters.Int('num_layers', 1, 3)):\n",
    "        model.add(layers.Dense(hyper_parameters.Int(f'units_{i+2}', min_value=32, max_value=256, step=32),\n",
    "                               activation=hyper_parameters.Choice(f'activation_{i+2}', ['relu', 'tanh', 'leaky_relu'])))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=hyper_parameters.Choice('learning_rate', [0.01, 0.001, 0.0001])),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test_tf, y_test_tf):\n",
    "    test_mae = model.evaluate(X_test_tf, y_test_tf)\n",
    "    return test_mae\n",
    "\n",
    "\n",
    "def cross_validate_model(model_builder, X_np, y_np, k_fold):\n",
    "    fold_mae_scores = []\n",
    "    for fold_num, (train_index, test_index) in enumerate(k_fold.split(X_np), start=1):\n",
    "        print(f\"Processing fold {fold_num}/{k_fold.get_n_splits()}\")\n",
    "        X_train_fold, X_test_fold = X_np[train_index], X_np[test_index]\n",
    "        y_train_fold, y_test_fold = y_np[train_index], y_np[test_index]\n",
    "\n",
    "        X_train_tf = tf.convert_to_tensor(X_train_fold, dtype=tf.float32)\n",
    "        X_test_tf = tf.convert_to_tensor(X_test_fold, dtype=tf.float32)\n",
    "        y_train_tf = tf.convert_to_tensor(y_train_fold, dtype=tf.float32)\n",
    "        y_test_tf = tf.convert_to_tensor(y_test_fold, dtype=tf.float32)\n",
    "\n",
    "        model = model_builder(X_train_tf)\n",
    "        model.fit(X_train_tf, y_train_tf, epochs=50,\n",
    "                  batch_size=32, validation_data=(X_test_tf, y_test_tf))\n",
    "\n",
    "        fold_mae = evaluate_model(model, X_test_tf, y_test_tf)\n",
    "        fold_mae_scores.append(fold_mae)\n",
    "\n",
    "    average_mae = np.mean(fold_mae_scores)\n",
    "    print(f'Average MAE across {k_fold.get_n_splits()} folds: {average_mae}')\n",
    "    return average_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the values used and training and testing the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = preprocess_data(dataset)\n",
    "\n",
    "X = dataset.drop('SettlementValue', axis=1)\n",
    "y = dataset['SettlementValue']\n",
    "\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "\n",
    "print(\"Base model results: No hyperparameter tuning:\")\n",
    "test_results.append(cross_validate_model(base_model, X_np, y_np, k_fold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the random search hyper-parameter tuner and evaluating the new model with the tuned hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    lambda hp: build_model(hp, X_np.shape[1]),\n",
    "    objective='val_mae',\n",
    "    max_trials=15,\n",
    "    executions_per_trial=2,\n",
    "    directory='tuner_results',\n",
    "    project_name='neural_network_test'\n",
    ")\n",
    "\n",
    "# Use a single train-test split for hyperparameter tuning\n",
    "X_train_tf = tf.convert_to_tensor(X_np, dtype=tf.float32)\n",
    "y_train_tf = tf.convert_to_tensor(y_np, dtype=tf.float32)\n",
    "\n",
    "tuner.search(X_train_tf, y_train_tf, epochs=50, batch_size=32,\n",
    "             validation_split=0.2)\n",
    "\n",
    "best_hyper_parameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "\n",
    "def tuned_model_builder(X_train_tf):\n",
    "    return build_model(best_hyper_parameters, X_train_tf.shape[1])\n",
    "\n",
    "\n",
    "test_results.append(cross_validate_model(\n",
    "    tuned_model_builder, X_np, y_np, k_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of the untuned and tuned models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Average Mean Absolute Error for untuned model:\")\n",
    "print(test_results[0])\n",
    "\n",
    "print(\"Average Mean Absolute Error for tuned model:\")\n",
    "print(test_results[1])\n",
    "\n",
    "print(f'Best Hyper Parameters \\n {best_hyper_parameters.get_config()}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
